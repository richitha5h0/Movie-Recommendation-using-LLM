# Movie-Recommendation-using-LLM

Overview

The Movie Recommendation System is built using a Large Language Model (LLM)-powered semantic search pipeline that understands natural language queries and recommends movies based on meaning rather than simple keyword matching. The system uses advanced sentence embeddings generated by the all-MiniLM-L6-v2 transformer model to capture contextual relationships within movie plots. This allows the model to interpret user queries such as “Telugu action movies after 2015,” “romantic comedy with high ratings,” or “Hollywood thriller with strong female lead,” and identify movies with plots and metadata that align with the user's intent. By combining rule-based filtering and embedding-based similarity comparison, the system provides highly relevant and intelligent movie recommendations.
 
 LLM-Based Recommendation Pipeline
 
First, the dataset containing movie titles, genres, plots, posters, ratings, languages, and release years is loaded and cleaned to ensure consistency across fields. Missing poster links are replaced with fallback poster images, release years are converted into standard integer format, and ratings are converted into numerical form. The languages column is cleaned and standardized to ensure correct filtering when the user requests movies in a specific language such as Telugu, Tamil, English, Hindi, Malayalam, or Kannada. Once preprocessing is completed, the plot of each movie is passed into the all-MiniLM-L6-v2 Sentence Transformer model, which computes a fixed-length embedding vector that represents the semantic meaning of the plot. These embeddings are precomputed and stored to make the recommendation process fast and efficient.

After preprocessing the dataset, user queries submitted through the UI are cleaned, lowercased, and analyzed for explicit filters such as genre, language, rating range, and release year constraints. If the query includes keywords like “action,” “romance,” “thriller,” “comedy,” or “horror,” the system applies genre-based filtering. Similarly, if the query contains a language name, the dataset is filtered accordingly. Conditions like “rating above 7” or “movies after 2012” are also identified and applied. These rule-based filters narrow down the dataset so that only relevant movies undergo semantic comparison.

Once the filtered subset is prepared, the user’s query text is passed through the same Sentence Transformer model to generate a query embedding. This embedding is then compared with the embeddings of the filtered movies using cosine similarity, allowing the system to determine which movies are semantically closest to the meaning of the query. The top results with the highest similarity scores are selected as the final recommendations. Each recommendation includes complete metadata such as the movie title, genre, languages, year, plot summary, poster image, rating, and trailer link if available.

The model operates through a Flask backend, where routes handle user input, preprocessing, LLM encoding, similarity computation, and result rendering. HTML templates display the intro page, login page, home page, and recommendation results in a visually appealing format. This end-to-end pipeline allows users to interact naturally with the system while receiving intelligent, context-aware recommendations powered by LLM-based semantic understanding. The system’s performance and accuracy depend on the quality of embeddings and the strength of the semantic representation learned by the underlying transformer model, making it significantly superior to traditional keyword-based movie recommendation systems.
